---
title: Quickstart
description: Get up and running with Uno LLM Gateway in minutes.
---

This guide will walk you through setting up the Uno LLM Gateway locally and making your first LLM call.

## Prerequisites

- [Docker](https://www.docker.com/products/docker-desktop/) and Docker Compose.
- [Go 1.25+](https://go.dev/doc/install) (if you want to use the SDK).

## 1. Start Uno

Clone the repository and start Uno with Docker Compose:

```bash
git clone github.com/praveen001/uno
cd uno/deployments
docker compose up -d
```

This starts the complete stack:
- **Uno App** - Backend API (port 8080) and Frontend UI (port 3000)
- **PostgreSQL** - Primary database
- **Redis** - Caching layer
- **ClickHouse** - Analytics and telemetry storage
- **OpenTelemetry Collector** - Trace and metrics collection

## 2. Open the Dashboard

Once the services are running, open `http://localhost:3000` in your browser.

<Tip>
**For Development**: If you want to run the backend and frontend locally (for development), use the dev compose file instead:

```bash
# Start only dependencies
docker compose -f docker-compose.dev.yaml up -d

# Run backend locally
go run main.go agent-server

# Run frontend locally (in another terminal)
cd frontend && npm install && npm start
```
</Tip>

## 3. Configure a Provider

1.  Navigate to the **Providers** section in the Dashboard.
2.  Click **Add Provider** and select **OpenAI**.
3.  Enter your OpenAI API Key and click **Save**.
4.  Go to **Virtual Keys** and create a new key for your project. Note down the key.

## 4. Make Your First Call

Now, use the Uno SDK to make an LLM call through the gateway.

```go
package main

import (
    "context"
    "fmt"
    "github.com/praveen001/uno/pkg/gateway/sdk"
    "github.com/praveen001/uno/pkg/llm"
    "github.com/praveen001/uno/pkg/llm/responses"
    "github.com/praveen001/uno/internal/utils"
)

func main() {
    // Initialize client in Gateway Mode
    client, _ := sdk.NewClient(&sdk.ClientOptions{
        Endpoint:    "http://localhost:6060",
        VirtualKey:  "your_virtual_key_here", // The ux_... key
    })

    model := client.NewLLM(sdk.LLMOptions{
        Provider: llm.ProviderNameOpenAI,
        Model:    "gpt-4o",
    })

    resp, _ := model.NewResponses(context.Background(), &responses.Request{
        Input: responses.InputUnion{
            OfString: utils.Ptr("Hello Uno!"),
        },
    })

    fmt.Println(resp.Output[0].OfOutputMessage.Content[0].OfOutputText.Text)
}
```

## Next Steps

Now that you have Uno running, explore more advanced features:

- [Text Generation](/gateway/sdk/text-generation) - Deep dive into LLM calls.
- [Tool Calling](/gateway/sdk/tool-calling) - Extend models with custom functions.
- [Reasoning](/gateway/sdk/reasoning) - Work with chain-of-thought models.
